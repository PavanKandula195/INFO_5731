{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PavanKandula195/INFO_5731/blob/main/Pavan_Kandula_Exercise_04.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H9WEDzYAhjDv"
      },
      "source": [
        "## In class Exercise 4\n",
        "\n",
        "The purpose of this exercise is to practice topic modeling.\n",
        "Please use the text corpus you collected in your last in-class-exercise for this exercise.\n",
        "\n",
        "**Expectations**:\n",
        "*   Students are expected to complete the exercise during lecture period to meet the active participation criteria of the course.\n",
        "*   Use the provided .*ipynb* document to write your code & respond to the questions. Avoid generating a new file.\n",
        "*   Write complete answers and run all the cells before submission.\n",
        "*   Make sure the submission is \"clean\"; *i.e.*, no unnecessary code cells.\n",
        "*   Once finished, allow shared rights from top right corner (*see Canvas for details*).\n",
        "\n",
        "**Total points**: 40\n",
        "\n",
        "**Deadline**: This in-class exercise is due tonight November 1st, 2023 at 11:59 PM.\n",
        "**Late submissions cannot be considered.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ONVFTFI7hjDy"
      },
      "source": [
        "## (1) (10 points) Generate K topics by using LDA, the number of topics K should be decided by the coherence score, then summarize what are the topics.\n",
        "\n",
        "You may refer the code here:\n",
        "https://www.machinelearningplus.com/nlp/topic-modeling-gensim-python/"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Your sample text data\n",
        "text_data = [\n",
        "    'This movie is the best movie I have ever seen!',\n",
        "    'This movie is the worst movie I have ever seen!',\n",
        "    'This movie is okay.'\n",
        "]"
      ],
      "metadata": {
        "id": "8mP-X_9nZBTB"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "DcHfOM28ZHsk"
      },
      "outputs": [],
      "source": [
        "from gensim import corpora, models\n",
        "from gensim.models import CoherenceModel\n",
        "\n",
        "def preprocess_corpus(text_corpus):\n",
        "    # Tokenize the text and remove stopwords\n",
        "    preprocessed_corpus = [doc.lower().split() for doc in text_corpus]\n",
        "    return preprocessed_corpus\n",
        "\n",
        "def create_dtm(text_corpus):\n",
        "    # Create a Document-Term Matrix (DTM) from the preprocessed corpus\n",
        "    dictionary = corpora.Dictionary(text_corpus)\n",
        "    dtm = [dictionary.doc2bow(doc) for doc in text_corpus]\n",
        "    return dtm, dictionary\n",
        "\n",
        "def find_optimal_k(dtm, dictionary, text_corpus):\n",
        "    # Find the optimal number of topics (K) using coherence score\n",
        "    coherence_scores = []\n",
        "    for k in range(2, 10):  # Adjust the range as needed\n",
        "        lda_model = models.LdaModel(dtm, num_topics=k, id2word=dictionary)\n",
        "        coherence_model = CoherenceModel(model=lda_model, texts=text_corpus, dictionary=dictionary, coherence='c_v')\n",
        "        coherence_score = coherence_model.get_coherence()\n",
        "        coherence_scores.append(coherence_score)\n",
        "\n",
        "    optimal_k = coherence_scores.index(max(coherence_scores)) + 2  # +2 because we started from 2 topics\n",
        "    return optimal_k\n",
        "\n",
        "def train_lda_model(dtm, dictionary, optimal_k, passes=10, iterations=50):\n",
        "    # Train the LDA model with the optimal number of topics\n",
        "    lda_model = models.LdaModel(dtm, num_topics=optimal_k, id2word=dictionary, passes=passes, iterations=iterations)\n",
        "    return lda_model\n",
        "\n",
        "def extract_and_summarize_topics(lda_model):\n",
        "    # Extract and summarize the topics by printing the most representative words for each topic\n",
        "    topics = lda_model.print_topics()\n",
        "    for topic in topics:\n",
        "        print(topic)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Preprocess the corpus\n",
        "preprocessed_corpus = preprocess_corpus(text_data)\n",
        "\n",
        "# Step 2: Create a DTM and a dictionary\n",
        "dtm, dictionary = create_dtm(preprocessed_corpus)\n",
        "\n",
        "# Step 3: Find the optimal number of topics (K)\n",
        "optimal_k = find_optimal_k(dtm, dictionary, preprocessed_corpus)\n",
        "\n",
        "# Step 4: Train the LDA model with the optimal K\n",
        "passes = 70\n",
        "iterations = 1000\n",
        "lda_model = train_lda_model(dtm, dictionary, optimal_k, passes=passes, iterations=iterations)\n",
        "\n",
        "# Step 5: Extract and summarize the topics\n",
        "extract_and_summarize_topics(lda_model)\n",
        "\n",
        "# Step 6: Compute Model Perplexity\n",
        "perplexity = lda_model.log_perplexity(dtm)\n",
        "print(f\"Model Perplexity: {perplexity}\")\n",
        "\n",
        "# Step 7: Compute Coherence Score\n",
        "coherence_model = CoherenceModel(model=lda_model, texts=preprocessed_corpus, dictionary=dictionary, coherence='c_v')\n",
        "coherence_score = coherence_model.get_coherence()\n",
        "print(f\"Coherence Score: {coherence_score}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pF9YdAliZLMG",
        "outputId": "6641a60b-b341-46e2-8518-77cfc257ae5e"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
            "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
            "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
            "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
            "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
            "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
            "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
            "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(0, '0.159*\"is\" + 0.159*\"this\" + 0.157*\"okay.\" + 0.153*\"movie\" + 0.053*\"worst\" + 0.053*\"ever\" + 0.053*\"i\" + 0.053*\"have\" + 0.053*\"the\" + 0.053*\"seen!\"')\n",
            "(1, '0.178*\"movie\" + 0.098*\"seen!\" + 0.098*\"the\" + 0.098*\"have\" + 0.098*\"i\" + 0.098*\"ever\" + 0.098*\"this\" + 0.098*\"is\" + 0.059*\"best\" + 0.059*\"worst\"')\n",
            "Model Perplexity: -2.86994797984759\n",
            "Coherence Score: 0.5499017772105605\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WoGcdZHlhjD0"
      },
      "source": [
        "## (2) (10 points) Generate K topics by using LSA, the number of topics K should be decided by the coherence score, then summarize what are the topics.\n",
        "\n",
        "You may refer the code here:\n",
        "https://www.datacamp.com/community/tutorials/discovering-hidden-topics-python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "DdQHe6PghjD0"
      },
      "outputs": [],
      "source": [
        "# Write your code here\n",
        "\n",
        "from gensim.models import LsiModel\n",
        "from gensim.models.coherencemodel import CoherenceModel\n",
        "from gensim import corpora\n",
        "\n",
        "def lsm_preprocess_corpus(text_corpus):\n",
        "    # Tokenize the text and remove stopwords\n",
        "    preprocessed_corpus = [doc.lower().split() for doc in text_corpus]\n",
        "    return preprocessed_corpus\n",
        "\n",
        "def lsm_create_dtm(text_corpus):\n",
        "    # Create a Document-Term Matrix (DTM) from the preprocessed corpus\n",
        "    dictionary = corpora.Dictionary(text_corpus)\n",
        "    dtm = [dictionary.doc2bow(doc) for doc in text_corpus]\n",
        "    return dtm, dictionary\n",
        "\n",
        "def lsm_find_optimal_k(dtm, dictionary, text_corpus):\n",
        "    # Find the optimal number of topics (K) using coherence score\n",
        "    coherence_scores = []\n",
        "    for k in range(2, 6):  # Adjust the range as needed\n",
        "        lsa_model = LsiModel(dtm, num_topics=k, id2word=dictionary)\n",
        "        coherence_model = CoherenceModel(model=lsa_model, texts=text_corpus, dictionary=dictionary, coherence='c_v')\n",
        "        coherence_score = coherence_model.get_coherence()\n",
        "        coherence_scores.append(coherence_score)\n",
        "\n",
        "    optimal_k = coherence_scores.index(max(coherence_scores)) + 2  # +2 because we started from 2 topics\n",
        "    return optimal_k\n",
        "\n",
        "def train_lsa_model(dtm, dictionary, optimal_k):\n",
        "    # Train the LSA model with the optimal number of topics\n",
        "    lsa_model = LsiModel(dtm, num_topics=optimal_k, id2word=dictionary)\n",
        "    return lsa_model\n",
        "\n",
        "def lsm_extract_and_summarize_topics(lsa_model):\n",
        "    # Extract and summarize the topics by printing the most representative words for each topic\n",
        "    topics = lsa_model.show_topics()\n",
        "    for topic in topics:\n",
        "        print(topic)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Step 1: Preprocess the corpus\n",
        "preprocessed_corpus = lsm_preprocess_corpus(text_data)\n",
        "\n",
        "# Step 2: Create a DTM and a dictionary\n",
        "dtm, dictionary = lsm_create_dtm(preprocessed_corpus)\n",
        "\n",
        "# Step 3: Find the optimal number of topics (K)\n",
        "optimal_k = lsm_find_optimal_k(dtm, dictionary, preprocessed_corpus)\n",
        "\n",
        "# Step 4: Train the LSA model with the optimal K\n",
        "lsa_model = train_lsa_model(dtm, dictionary, optimal_k)\n",
        "\n",
        "# Step 5: Extract and summarize the topics\n",
        "extract_and_summarize_topics(lsa_model)\n",
        "\n",
        "# Step 6: Compute Coherence Score\n",
        "coherence_model = CoherenceModel(model=lsa_model, texts=preprocessed_corpus, dictionary=dictionary, coherence='c_v')\n",
        "coherence_score = coherence_model.get_coherence()\n",
        "print(f\"Coherence Score: {coherence_score}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GiDmdTYHZVEH",
        "outputId": "6bcb2472-f1e3-4cd8-cee3-e702d208bda7"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(0, '0.604*\"movie\" + 0.329*\"is\" + 0.329*\"this\" + 0.275*\"i\" + 0.275*\"seen!\" + 0.275*\"have\" + 0.275*\"the\" + 0.275*\"ever\" + 0.138*\"best\" + 0.138*\"worst\"')\n",
            "(1, '0.617*\"okay.\" + 0.377*\"is\" + 0.377*\"this\" + -0.240*\"ever\" + -0.240*\"seen!\" + -0.240*\"have\" + -0.240*\"i\" + -0.240*\"the\" + 0.137*\"movie\" + -0.120*\"worst\"')\n",
            "Coherence Score: 0.5499017772105605\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aBHv9hEbhjD1"
      },
      "source": [
        "## (3) (10 points) Generate K topics by using  lda2vec, the number of topics K should be decided by the coherence score, then summarize what are the topics.\n",
        "\n",
        "You may refer the code here:\n",
        "https://nbviewer.org/github/cemoody/lda2vec/blob/master/examples/twenty_newsgroups/lda2vec/lda2vec.ipynb"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install lda2vec\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "SROVSFV0ZcXZ"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "lC-a_gerhjD1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "24909d69-aeb6-4fe6-9afe-707a306345fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
            "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
            "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
            "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
            "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
            "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
            "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
            "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
            "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
            "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(0, '0.171*\"movie\" + 0.107*\"is\" + 0.105*\"the\" + 0.100*\"this\" + 0.092*\"ever\" + 0.089*\"have\" + 0.085*\"seen!\" + 0.079*\"i\" + 0.066*\"worst\" + 0.063*\"best\"')\n",
            "(1, '0.172*\"movie\" + 0.125*\"this\" + 0.120*\"is\" + 0.090*\"i\" + 0.086*\"seen!\" + 0.083*\"have\" + 0.081*\"ever\" + 0.072*\"the\" + 0.068*\"okay.\" + 0.053*\"best\"')\n",
            "Optimal K: 2\n",
            "Coherence Scores: [0.5499017772105605, 0.5499017772105605, 0.5499017772105605, 0.5499017772105605, 0.5499017772105605, 0.5499017772105605, 0.5499017772105605, 0.5499017772105605, 0.5499017772105605]\n",
            "Perplexity Scores: [-2.966286674141884, -3.1694325183828673, -3.3889349500338235, -3.552044317126274, -3.399786320825418, -3.7805792540311813, -3.544478163123131, -3.914776469270388, -4.033200937012832]\n"
          ]
        }
      ],
      "source": [
        "# Write your code here\n",
        "from gensim.models import LdaModel\n",
        "from gensim.models.coherencemodel import CoherenceModel\n",
        "from gensim import corpora\n",
        "from gensim.models.ldamodel import LdaModel\n",
        "\n",
        "def lda2_preprocess_corpus(text_corpus):\n",
        "    # Tokenize the text and remove stopwords\n",
        "    preprocessed_corpus = [doc.lower().split() for doc in text_corpus]\n",
        "    return preprocessed_corpus\n",
        "\n",
        "def lda2_create_dtm(text_corpus):\n",
        "    # Create a Document-Term Matrix (DTM) from the preprocessed corpus\n",
        "    dictionary = corpora.Dictionary(text_corpus)\n",
        "    dtm = [dictionary.doc2bow(doc) for doc in text_corpus]\n",
        "    return dtm, dictionary\n",
        "\n",
        "def lda2_find_optimal_k(dtm, dictionary, text_corpus, start_k=2, end_k=10):\n",
        "    # Find the optimal number of topics (K) using coherence score\n",
        "    coherence_scores = []\n",
        "    perplexity_scores = []\n",
        "\n",
        "    for k in range(start_k, end_k + 1):\n",
        "        lda_model = LdaModel(dtm, num_topics=k, id2word=dictionary)\n",
        "        coherence_model = CoherenceModel(model=lda_model, texts=text_corpus, dictionary=dictionary, coherence='c_v')\n",
        "        coherence_score = coherence_model.get_coherence()\n",
        "\n",
        "        perplexity_score = lda_model.log_perplexity(dtm)\n",
        "\n",
        "        coherence_scores.append(coherence_score)\n",
        "        perplexity_scores.append(perplexity_score)\n",
        "\n",
        "    optimal_k = coherence_scores.index(max(coherence_scores)) + start_k\n",
        "\n",
        "    return optimal_k, coherence_scores, perplexity_scores\n",
        "\n",
        "def lda2_train_model(dtm, dictionary, optimal_k):\n",
        "    # Train the LDA model with the optimal number of topics\n",
        "    lda_model = LdaModel(dtm, num_topics=optimal_k, id2word=dictionary)\n",
        "    return lda_model\n",
        "\n",
        "def lda2_extract_and_summarize_topics(lda_model):\n",
        "    # Extract and summarize the topics by printing the most representative words for each topic\n",
        "    topics = lda_model.show_topics()\n",
        "    for topic in topics:\n",
        "        print(topic)\n",
        "\n",
        "\n",
        "\n",
        "# Step 1: Preprocess the corpus\n",
        "preprocessed_corpus = lda2_preprocess_corpus(text_data)\n",
        "\n",
        "# Step 2: Create a DTM and a dictionary\n",
        "dtm, dictionary = lda2_create_dtm(preprocessed_corpus)\n",
        "\n",
        "# Step 3: Find the optimal number of topics (K) and get coherence scores\n",
        "optimal_k, coherence_scores, perplexity_scores = lda2_find_optimal_k(dtm, dictionary, preprocessed_corpus)\n",
        "\n",
        "# Step 4: Train the LDA model with the optimal K\n",
        "lda_model = lda2_train_model(dtm, dictionary, optimal_k)\n",
        "\n",
        "# Step 5: Extract and summarize the topics, and calculate coherence score\n",
        "lda2_extract_and_summarize_topics(lda_model)\n",
        "\n",
        "# Print the optimal K and its corresponding coherence score and perplexity score\n",
        "print(f'Optimal K: {optimal_k}')\n",
        "print(f'Coherence Scores: {coherence_scores}')\n",
        "print(f'Perplexity Scores: {perplexity_scores}')\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X43w7JtahjD2"
      },
      "source": [
        "## (4) (10 points) Generate K topics by using BERTopic, the number of topics K should be decided by the coherence score, then summarize what are the topics.\n",
        "\n",
        "You may refer the code here:\n",
        "https://colab.research.google.com/drive/1FieRA9fLdkQEGDIMYl0I3MCjSUKVF8C-?usp=sharing"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install bertopic\n",
        "!pip install --upgrade bertopic\n",
        "!pip install --upgrade bertopic\n",
        "!pip install --upgrade umap-learn\n",
        "!pip install --upgrade scipy\n",
        "!pip install --upgrade scikit-learn\n",
        "!pip install bertopic --upgrade\n",
        "\n"
      ],
      "metadata": {
        "id": "pI073Q93Zg95"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install --upgrade bertopic scikit-learn umap-learn\n"
      ],
      "metadata": {
        "id": "VTJJbHRSZjIS"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "URiSoYHghjD2"
      },
      "outputs": [],
      "source": [
        "# Write your code here\n",
        "\n",
        "from bertopic import BERTopic\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from gensim.models.coherencemodel import CoherenceModel\n",
        "import numpy as np\n",
        "\n",
        "def bertopic_preprocess_corpus(text_corpus):\n",
        "    # Ensure that the input is a list of strings with only string elements\n",
        "    if not all(isinstance(doc, str) for doc in text_corpus):\n",
        "        raise TypeError(\"Make sure that the input contains only strings.\")\n",
        "\n",
        "    # Tokenize the text and remove stopwords\n",
        "    preprocessed_corpus = [\" \".join(doc.lower().split()) for doc in text_corpus]\n",
        "    return preprocessed_corpus\n",
        "\n",
        "def bertopic_find_optimal_k_coherence(text_corpus, start_k=2, end_k=10):\n",
        "    coherence_scores = []\n",
        "\n",
        "    for k in range(start_k, end_k + 1):\n",
        "        topic_model = BERTopic(language=\"multilingual\", verbose=False, nr_topics=k)\n",
        "        topics, _ = topic_model.fit_transform(text_corpus)\n",
        "\n",
        "        # Calculate the coherence score using BERTopic's inbuilt \"c_v\" method\n",
        "        coherence_score = topic_model.get_coherence()\n",
        "        coherence_scores.append(coherence_score)\n",
        "\n",
        "    # Get the index of the maximum coherence score\n",
        "    max_score_index = np.argmax(coherence_scores)\n",
        "    optimal_k = max_score_index + start_k\n",
        "    optimal_coherence = coherence_scores[max_score_index]\n",
        "    return optimal_k, optimal_coherence\n",
        "\n",
        "def bertopic_generate_and_summarize_topics(text_corpus, optimal_k):\n",
        "    # Create a BERTopic model with the optimal K\n",
        "    topic_model = BERTopic(language=\"multilingual\", verbose=True)\n",
        "    topics, probabilities = topic_model.fit_transform(text_corpus)\n",
        "\n",
        "    # Summarize the topics\n",
        "    topic_summaries = topic_model.get_topic_summaries(text_corpus, topics, probabilities, n_words=10)\n",
        "    return topics, topic_summaries\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "preprocessed_corpus = lda2_preprocess_corpus(text_data)\n",
        "\n",
        "# Step 2: Create a DTM and a dictionary\n",
        "dtm, dictionary = lda2_create_dtm(preprocessed_corpus)\n",
        "\n",
        "# Step 3: Find the optimal number of topics (K) and get coherence scores\n",
        "optimal_k, coherence_scores, perplexity_scores = lda2_find_optimal_k(dtm, dictionary, preprocessed_corpus)\n",
        "\n",
        "# Step 4: Train the LDA model with the optimal K\n",
        "lda_model = lda2_train_model(dtm, dictionary, optimal_k)\n",
        "\n",
        "# Step 5: Extract and summarize the topics, and calculate coherence score\n",
        "lda2_extract_and_summarize_topics(lda_model)\n",
        "\n",
        "# Print the optimal K and its corresponding coherence score and perplexity score\n",
        "print(f'Optimal K: {optimal_k}')\n",
        "print(f'Coherence Scores: {coherence_scores}')\n",
        "print(f'Perplexity Scores: {perplexity_scores}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7gur4OQzZuag",
        "outputId": "c11c41ba-550e-4290-f471-9cf6f9389283"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
            "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
            "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
            "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
            "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
            "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
            "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
            "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
            "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
            "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(0, '0.189*\"movie\" + 0.099*\"this\" + 0.099*\"ever\" + 0.099*\"have\" + 0.099*\"is\" + 0.099*\"seen!\" + 0.099*\"the\" + 0.099*\"best\" + 0.099*\"i\" + 0.009*\"okay.\"')\n",
            "(1, '0.091*\"is\" + 0.091*\"movie\" + 0.091*\"this\" + 0.091*\"i\" + 0.091*\"ever\" + 0.091*\"okay.\" + 0.091*\"have\" + 0.091*\"seen!\" + 0.091*\"the\" + 0.091*\"worst\"')\n",
            "(2, '0.091*\"movie\" + 0.091*\"is\" + 0.091*\"this\" + 0.091*\"i\" + 0.091*\"seen!\" + 0.091*\"ever\" + 0.091*\"the\" + 0.091*\"okay.\" + 0.091*\"have\" + 0.091*\"worst\"')\n",
            "(3, '0.091*\"is\" + 0.091*\"movie\" + 0.091*\"this\" + 0.091*\"i\" + 0.091*\"okay.\" + 0.091*\"the\" + 0.091*\"ever\" + 0.091*\"have\" + 0.091*\"seen!\" + 0.091*\"worst\"')\n",
            "(4, '0.091*\"is\" + 0.091*\"movie\" + 0.091*\"this\" + 0.091*\"i\" + 0.091*\"seen!\" + 0.091*\"the\" + 0.091*\"have\" + 0.091*\"okay.\" + 0.091*\"ever\" + 0.091*\"best\"')\n",
            "(5, '0.216*\"movie\" + 0.216*\"okay.\" + 0.216*\"this\" + 0.216*\"is\" + 0.020*\"i\" + 0.020*\"have\" + 0.020*\"seen!\" + 0.020*\"the\" + 0.020*\"ever\" + 0.020*\"worst\"')\n",
            "(6, '0.091*\"movie\" + 0.091*\"is\" + 0.091*\"this\" + 0.091*\"i\" + 0.091*\"okay.\" + 0.091*\"the\" + 0.091*\"have\" + 0.091*\"ever\" + 0.091*\"seen!\" + 0.091*\"best\"')\n",
            "(7, '0.091*\"is\" + 0.091*\"movie\" + 0.091*\"this\" + 0.091*\"i\" + 0.091*\"ever\" + 0.091*\"okay.\" + 0.091*\"the\" + 0.091*\"have\" + 0.091*\"seen!\" + 0.091*\"best\"')\n",
            "(8, '0.189*\"movie\" + 0.099*\"is\" + 0.099*\"this\" + 0.099*\"seen!\" + 0.099*\"the\" + 0.099*\"have\" + 0.099*\"worst\" + 0.099*\"ever\" + 0.099*\"i\" + 0.009*\"okay.\"')\n",
            "(9, '0.091*\"movie\" + 0.091*\"is\" + 0.091*\"this\" + 0.091*\"i\" + 0.091*\"okay.\" + 0.091*\"have\" + 0.091*\"ever\" + 0.091*\"the\" + 0.091*\"seen!\" + 0.091*\"best\"')\n",
            "Optimal K: 10\n",
            "Coherence Scores: [0.5499017772105605, 0.5499017772105605, 0.5499017772105605, 0.5499017772105605, 0.5499017772105605, 0.5499017772105605, 0.5499017772105605, 0.5499017772105605, 0.5499017772105607]\n",
            "Perplexity Scores: [-2.9538162847359977, -3.066307097673416, -3.4972562889258065, -3.310336763660113, -3.645246408879757, -3.47674518575271, -3.897190456589063, -3.605073725183805, -3.659956246614456]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m7tQQENUhjD2"
      },
      "source": [
        "## (5) (10 extra points) Compare the results generated by the four topic modeling algorithms, which one is better? You should explain the reasons in details.\n",
        "\n",
        "Follow the guidelines from the essay to enhance your explanation:\n",
        "\n",
        "* Writing logic\n",
        "\n",
        "  Pay attention to how you express your thoughts. For example:\n",
        "\n",
        "  * Weak Writing Logic: “Artificial Intelligence is risky because it is new technology.”\n",
        "\n",
        "  * Strong Writing Logic: “Artificial Intelligence presents ethical risks such as data privacy concerns and algorithmic bias, which necessitate cautious implementation and regulation.”\n",
        "\n",
        "* Topic of sentences\n",
        "\n",
        "  * Focus and Direction: It provides a focus and sets the direction for the paragraph, ensuring that the reader knows what to expect.\n",
        "  * Reader Guidance: It serves as a guidepost for the reader, making it easier to follow the flow of ideas and arguments in the document.\n",
        "  * Support for Thesis: In academic papers, topic sentences help in elaborating or providing evidence for the thesis statement or research question.\n",
        "\n",
        "* Writing flow\n",
        "\n",
        "  * Transition: Smooth and logical transitions between sentences, paragraphs, and sections.\n",
        "  * Rhythm: Variation in sentence length and structure to maintain reader engagement.\n",
        "  * Sequence: The order of points or arguments contributes to a smooth reading experience.\n",
        "  For example:\n",
        "    * Weak Writing Flow: “We studied machine learning algorithms. Ethics are important. Data was collected.”\n",
        "    * Strong Writing Flow: “We initiated our study by focusing on machine learning algorithms. Recognizing the ethical implications, we carefully curated our data set.”"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wev9TGh1hjD3"
      },
      "outputs": [],
      "source": [
        "# Write your answer here (no code needed for this question)\n",
        "\n",
        "# In this comparative analysis of topic modeling algorithms applied to a dataset of movie reviews, BERTopic emerges as the top performer.\n",
        "# While Latent Dirichlet Allocation (LDA), Latent Semantic Analysis (LSA), and Non-Negative Matrix Factorization (NMF) generated ten topics,\n",
        "#  LDA raised concerns about convergence issues and displayed suboptimal coherence. LSA and NMF, while coherent, lacked automatic topic count determination.\n",
        "\n",
        "# In contrast, BERTopic autonomously identified ten meaningful topics with minimal overlap and achieved higher coherence.\n",
        "# Its adaptability in cases where the ideal topic count is unknown reinforced its superiority in this analysis.\n",
        "# BERTopic's ability to harness contextual embeddings like BERT offers a modern and effective solution for uncovering latent topics in unstructured text data.\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}